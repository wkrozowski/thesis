\chapter{Introduction}
\label{chapter:introduction}
One of the motivations for the mathematical study of the models of computation stems from the desire for precise and formal reasoning about the correctness of computer systems. These theoretical foundations enable formal verification experts to prove that systems deployed in safety-critical areas, such as avionics or healthcare, behave as expected. In theoretical computer science it is customary to model computations as state transition systems, which are discrete models where a set of states is equipped with a notion of one-step observable behaviour, describing how the system evolves. Typical examples include finite automata, Kripke frames, and Markov chains among many others. 

	This central topic of this thesis are axiomatisations of behaviour of transition systems. By this we mean providing expression languages for representing the behaviour of transition systems and the study of formal systems for reasoning about equivalence or similarity of behaviours represented by expressions of the interest. 
	
	The interest in axiomatising behaviour of transition systems originates from the seminal work of Kleene on regular expressions~\cite{Kleene:1951:Representation}.  In his influential paper from 1951, Kleene introduced deterministic finite automata (DFAs), which are the fundamental model of sequential deterministic computations. Each state of a DFA can be associated with a formal language, a collection of strings that are accepted starting from a given state. This characterises an important class of formal languages, known as regular languages. Classically, two states are equivalent if they recognise the same language. In the same paper, Kleene proposed regular expressions, which are an algebraic specification language for DFAs and proved that both formalisms are equally expressive through a result known nowadays as Kleene’s theorem. As an open problem, he left a completeness question: are there a finite number of rules that enable reasoning about language equivalence of regular expressions? 

Shortly after Kleene's paper, Redko~\cite{Redko:1964:Defining} demonstrated that one cannot use a finite number of equational axioms to axiomatise the language equivalence. But the search for axiomatisation made of more expressive rules continued. The first answer came in 1966 from Salomaa~\cite{Salomaa:1966:Two}, who presented two axiom systems. One was infinitary, and the other used finite equations along with an implicational rule encoding Arden's lemma~\cite{Arden:1961:Delayed} for formal languages. While Salomaa's implicational axiomatisation later became a blueprint for inference systems for reasoning about semantic equivalence or similarity of transition systems, this formal system was not algebraic. Essentially, the implicational rule relied on the productivity side-condition called empty word property (EWP) that caused the resulting axiomatisation to be unsound under substitution of letters by arbitrary expressions. This problem has motivated several researchers including Conway~\cite{Conway:2012:Regular}, Krob~\cite{Krob:1990:Complete} and Boffa~\cite{Boffa:1990:Une} to pursue the problem of obtaining algebraic axiomatisation of language equivalence of DFAs, eventually leading to a celebrated completeness result of Kozen~\cite{Kozen:1994:Completeness}. The inference system of Kozen is known nowadays under the name Kleene Algebra (KA) and it forms a basis of several formal systems for equational reasoning about imperative programs~\cite{Kozen:1996:Kleene}, packet-passing software defined networks~\cite{Anderson:2014:NetKAT}, and concurrent programs~\cite{Kappe:2017:Concurrent,Wagemaker:2019:Completeness} among many others.

Since Kleene, automata theorists have studied many variants of automata, including nondeterministic~\cite{Rabin:1959:Finite}, weighted~\cite{Schutzenberger:1961:Definition} and probabilistic~\cite{Rabin:1963:Probabilistic} ones, usually focusing on the notion of language equivalence or inclusion. At the advent of process algebra in the 1980s, Milner and Park brought the concept of bisimilarity~\cite{Park:1981:Concurrency}, a notion of equivalence finer than language equivalence, that was motivated by the needs of the study of concurrency theory and models such as labelled transition systems (LTSs). Essentially, language equivalence is a linear-time notion, as it hides the precise moment of resolving nondeterministic choice from the external observer. At the same time, bisimilarity allows for a more fine-grained comparison of behaviours by looking at the exact moment of resolving the nondeterministic choice. 

In his seminal paper from 1984, Milner~\cite{Milner:1984:Complete} considered a variant of LTSs that he called charts and studied the associated problem of axiomatising bisimilarity of charts. Milner observed that while the syntax of regular expression can be used to specify behaviours of charts, it is not expressive, that is there exist behaviours that cannot be specified using Kleene's syntax. Instead, he proposed a more general language called algebra of regular behaviours (ARB) featuring binders, action prefixing, and a recursion operator. Milner provided a suitable generalisation of Salomaa's non-algebraic axiomatisation and demonstrated its soundness and completeness with respect to bisimilarity of charts.   

The completeness results of Salomaa, Kozen and Milner mentioned above are prototypical instances of the vast strain of research that has been of particular interest to theoretical computer scientists for decades. Given a transition system model and an associated notion of semantic equivalence, having a complete axiomatisation allows one to reason about model behaviour through the syntactic manipulation of terms of the specification language, which is well-suited for implementation, automation, and formal reasoning. Each time when the needs of modelling computer systems result in a new transition system model or an associated notion of semantic equivalence, it is natural to ask about the complete axiomatisation. 

This thesis provides contributions to the above outlined field of axiomatisations of behaviours of transition systems in two orthogonal directions.
\begin{enumerate}
	\item The first part of the thesis is concerned with the study of formal systems for quantitative reasoning about behavioural metrics, that replace conventional notions of behavioural equivalence with a quantitative measure of how close the behaviour of two states of transition systems is.
	\item The second part focuses on probabilistic transition systems and presents a sound and complete axiomatisation of language equivalence of behaviours specified through the syntax of Probabilistic Regular Expressions.
	\end{enumerate}	
We now provide a brief outline of each of these directions.
\section{Behavioural Metrics}
In many contexts, especially when dealing with probabilistic or quantitative models, focusing on exact equivalence of behaviours such as language equivalence or bisimilarity is too restrictive. A tiny perturbation in observed probability or weights of transition can deem two states inequivalent.  Instead, it is often more meaningful to measure how far apart the behaviours of two states are. 

This has motivated the development of behavioural metrics, which endow the state spaces of transition systems with (pseudo)metric spaces quantifying the dissimilarity of states. In such a setting, states at distance zero are not necessarily the same, but rather equivalent with respect to some classical notion of behavioural equivalence. In a nutshell, equipping transition systems with such a notion of distance crucially relies on the possibility of lifting the distance between the states to the distance on the one-step observable behaviour of the transition system.

Behavioural distances first appeared in the context of probabilistic transition systems~\cite{Desharnais:2004:Metrics,Breugel:2001:Towards}. Here, one-step observable behaviour forms a probability distribution. In such a setting, in order to lift distances from the state space to one-step observable behaviour, one can rely on classic Kantorovich lifting from transportation theory~\cite{Villani:2009:Optimal}. 

Behavioural distances are not limited to probabilistic or weighted systems; instead, they can be defined meaningfully for a variety of transition systems~\cite{Baldan:2018:Coalgebraic}. One of the simplest instances is deterministic finite automata, which can be equipped with a shortest-distinguishing-word distance~\cite{Bonchi:2018:UpTo}, where the longer the smallest word that can witness inequivalence of two states is, the closer the behaviour of compared states is. To illustrate that, given an alphabet $\alphabet = \{a\}$, we have that a state recognising the language $\{a,aa, aaa\}$ is closer to the one recognising $\{a,aa,aaa,aaa\}$ rather than $\{a\}$. 

So far, the study of axiomatisations of behavioural distances have mainly focused on concrete probabilistic cases~\cite{Bacci:2018:Bisimilarity,Bacci:2018:TV,Bacci:2018:Algebraic}. Axiomatisations of other important instances of behavioural distances are still underexplored. The main goal of the first part of this thesis is to initiate the study of axiomatisations and completeness problems for behavioural distances beyond the concrete probabilistic instances. Our starting point is the work of Bacci, Bacci, Larsen and Mardare~\cite{Bacci:2018:Bisimilarity}, who gave a sound and complete axiomatisation of branching-time behavioural distance of terms of a probabilistic process calculus.

\section{Probabilistic Language Equivalence}
In his seminal work from 1963, Rabin introduced Probabilistic Automata~\cite{Rabin:1963:Probabilistic}. This model captures the simple notion of randomised computation and acts as an acceptor for probabilistic languages. Under such semantics, each word over some fixed alphabet is associated with a weight from the unit interval capturing how likely the word is to be accepted. Throughout the years, Probabilistic Automata were deeply studied from an algorithmic point of view~\cite{Kiefer:2011:Language} that eventually enabled the development of practical verification tools for randomised programs~\cite{Kiefer:2012:APEX}. 

In the process algebra community, Larsen and Skou~\cite{Larsen:1991:Bisimulation} devised a notion of probabilistic bisimilarity, while Stark and Smolka~\cite{Stark:2000:Complete} provided a probabilistic process calculus featuring binders and a recursion operator and gave a sound and complete axiomatisation of probabilistic bisimilarity of terms of their calculus. The later work of Silva and Sokolova~\cite{Silva:2011:Sound} showed that one can extend Stark and Smolka's system with additional axioms characterising probabilistic language equivalence to obtain a complete axiomatisation of language equivalence.

While the result of Silva and Sokolova enables the use of the process algebraic syntax of Stark and Smolka for reasoning about probabilistic language equivalence, it is natural to ask if one could obtain a similar picture to the one for the usual language equivalence. That is, to devise a simpler, binder-free specification language in the style of Kleene's Regular Expressions and provide a more streamlined axiomatisation in the style of Salomaa.
	
	This problem is the central motivation for the second part of this thesis. One of the main inspirations for that comes from the probabilistic pattern matching community, where researchers already considered Regular Expression-like operations to specify probabilistic languages~\cite{Ross:2000:Probabilistic}. They did so by replacing the union of languages and Kleene's star from the usual Regular Expression with their probabilistic counterparts, which respectively can be seen as a convex combination and a form of the Bernoulli process. At the same time, the precise connection of such syntaxes to the transition systems model was under-explored~\cite{Beeh:2017:Transformations} and the topic of axiomatisation was not tackled at all. 


\section{Coalgebra}
This thesis's subjects, that is behavioural metrics and probabilistic language equivalence, can be studied abstractly through the unifying framework of the universal coalgebra~\cite{Gumm:2000:Elements,Rutten:2000:Universal}. This framework provides an abstract and uniform treatment of transition systems through the language of category theory. Because of this, this thesis takes a coalgebraic point of view.

Generally speaking, transition systems can be seen as pairs consisting of a set of states and a transition function, mapping each state to its one-step behaviour. The coalgebraic outlook allows abstracting away the features of the one-step behaviour of the transition system, such as inputs, labels, nondeterminism, probability, and the like through the notion of a type, formally modelled as an endofunctor on the category of sets and functions. Given a type functor, one can uniformly instantiate abstract results concerning the transition systems of the interest. In particular, each type of functor canonically determines a notion of behavioural equivalence of states. Under mild set-theoretic size constraints on the type functor, one can construct a final coalgebra, which provides a universal domain of behaviours of transition systems of interest. For example, the final coalgebra for the functor describing deterministic automata is isomorphic to the set of all formal languages over some alphabet~\cite{Rutten:2000:Universal}. Concrete instances of coalgebraic behavioural equivalence usually capture variants of bisimilarity and coincide with the notions known for the literature such as bisimilarity of LTSs or probabilistic bisimilarity of Larsen and Skou~\cite{Vink:1999:Bisimulation}.  
		
	Modelling finer notions of semantic equivalence can be phrased by changing the base category over which the type functor is defined to a more structured setting than sets and functions. For example, one of the ways to model probabilistic language equivalence in the language of coalgebra is to work with coalgebras for an appropriate type functor over the category of positive convex algebras~\cite{Silva:2010:Generalizing,Silva:2011:Sound}. In this category, the final coalgebra is precisely carried by the set of all probabilistic languages over some alphabet. 	 

At the same time, the recent work on coalgebraic behavioural metrics~\cite{Baldan:2018:Coalgebraic} provided a categorical generalisation of Kantorovich lifting to lifting endofunctors over the category of sets to the category of pseudometric spaces and nonexpansive maps between them. Final coalgebras for type functors obtained through such liftings come equipped with a pseudometric between behaviours. Such a coalgebraic outlook enables generalising the notions of behavioural metrics beyond probabilistic transition systems. 

Using the theory of universal coalgebra for axiomatisation problems allows abstracting away the generic steps of completeness theorems and instantiating abstract categorical results to obtain concrete properties of transition systems of interest. For example, the recently developed theory of rational fixpoints~\cite{Milius:2010:Sound} for coalgebras for proper functors~\cite{Milius:2018:Proper} provides a useful generalisation of the notion of regular languages to coalgebraic generality. One of the concrete instantiations of such a theory enables characterising the analogue of regular languages in the case of probabilistic languages~\cite{Sokolova:2018:Proper} and underpins key results in the second part of the thesis.


\section{Overview of the thesis}
Having outlined the scope and the main aims of this thesis, we summarise below the content of each chapter of the thesis and provide reference to the main technical results. The description of each content chapter contains a table providing a high-level overview of the studied axiomatisation problem.
\subparagraph{Chapter 2} presents a sound and complete axiomatisation of \emph{shortest-distinguishing-word} distance between formal languages represented by regular expressions.
 The axiomatisation relies on a recently developed quantitative analogue of equational logic, allowing manipulation of rational-indexed judgements of the form $e \disteq{\e} f$ meaning the distance between terms $e$ and $f$ is less or equal to $\e$. The technical core of the chapter is dedicated to the completeness argument that draws techniques from order theory and Banach spaces to simplify the calculation of the behavioural distance to the point it can be then mimicked by axiomatic reasoning. 
 
\begin{center}

\begin{tabular}{ m{3cm}|m{10cm}}
  \hline
  \multicolumn{2}{c}{Summary of \Cref{chapter2}}\\
  \hline
  Model & DFAs\\
  Syntax & $e,f \in \RExp ::= \zero \mid \one \mid a \in \Sigma \mid e + f \mid e \seq f \mid e^\ast$ \\
  Semantics & shortest-distinguishing-word distance of languages \\
  Example fact & $a^\ast \disteq{1/4}a + 1 $\\
  Soundness & Theorem \Cref{c2:soundness} \\
  Completeness	& Theorem \Cref{c2:completeness} \\
  \hline
\end{tabular}
\end{center}
This chapter incorporates results from the following paper:

\printpublication{Rozowski:2024:Complete}


\subparagraph{Chapter 3} describes a sound and complete axiomatisation of behavioural metric for nondeterministic processes using Milner's charts~\cite{Milner:1984:Complete}---a model that generalises finite-state automata by incorporating variable outputs. Charts provide a compelling setting for studying behavioural distances because they shift the focus from language equivalence to bisimilarity.

To formalise this approach, we adopt string diagrams~\cite{Selinger_2010,piedeleu2023introduction} as our syntax of choice. String diagrams closely mirror the graphical structure of charts, while providing a rigorous formalism that supports inductive reasoning and compositional semantics. Unlike traditional algebraic syntaxes, which require additional mechanisms such as binders and substitution, string diagrams offer a variable-free representation where recursion naturally decomposes into simpler components. This makes them well-suited for reasoning about behavioural distances and aligns with broader efforts to axiomatise automata-theoretic equivalences through a unified diagrammatic framework~\cite{piedeleu2023finite,antoinecsl2025}.
\begin{figure}
	
\end{figure}
\begin{center}
\begin{tabular}{ m{3cm}|m{10cm}}
  \hline
  \multicolumn{2}{c}{Summary of \Cref{chapter3}}\\
  \hline
  Model & Milner's charts~\cite{Milner:1984:Complete}\\
  Syntax & $\tikzfig{lr-copy}\quad\tikzfig{lr-delete}\quad\tikzfig{lr-merge}\quad\tikzfig{lr-generate} \quad\tikzfig{cap-down} \quad\tikzfig{cup-down}\quad \scalar{a} \quad (a\in \alphabet)$ \\
  Semantics & bisimulation distance of regular behaviours\\
  Example fact & $\tikzfig{ex-diag-1-l} \disteq{1/4} \tikzfig{a-star-b}$\\
  Soundness & Theorem \Cref{c2:soundness} \\
  Completeness	& Theorem \Cref{c2:completeness} \\
  \hline
\end{tabular}
\end{center}
The findings presented in this chapter are the content of the following paper:

\printpublication{Rozowski:2025:Diagrammatic}


\subparagraph{Chapter 4} introduces Probabilistic Regular Expressions (PRE), a probabilistic analogue of regular expressions denoting probabilistic languages in which every word is assigned a probability of being generated.  PRE are formed through constants from an alphabet and regular operations of probabilistic choice, sequential composition, probabilistic Kleene star, identity and emptiness.  We present and prove the completeness of an inference system for reasoning about probabilistic language equivalence of PRE based on Salomaa’s axiomatisation of Kleene Algebra. The technical core of the chapter is devoted to the completeness proof, which relies on technical tools from the theory of convex algebra~\cite{Sokolova:2018:Proper}, arising from the rich structure of probabilistic languages. 
\begin{center}

\begin{tabular}{ m{3cm}|m{10cm}}
  \hline
  \multicolumn{2}{c}{Summary of \Cref{chapter4}}\\
  \hline
  Model & generative probabilistic transition systems~\cite{Glabbeek:1995:Reactive}\\
  Syntax & $e,f \in \RExp ::= \zero \mid \one \mid a \in \Sigma \mid e \oplus_p f \mid e \seq f \mid e^{\left[ p \right]}$ \\  Semantics & probabilistic language equivalence \\
  Example fact & $a \seq a^{\left[1/4\right]} \equiv a \oplus_{3/4} \left( a \seq a^{\left[1/4\right]}\seq a\right)$\\
  Soundness & Theorem \Cref{c2:soundness} \\
  Completeness 	& Theorem \Cref{c2:completeness} \\
  \hline
\end{tabular}
\end{center}
The results described in this chapter were published in the paper referenced below:

\printpublication{Rozowski:2024:Completeness}

\textbf{Chapter 5} sketches directions for the future work and concludes this thesis.

\section{Related work}
In this section, we survey the main strands of the related work, while we relegate the more detailed discussion to the respective content chapters. 

\subparagraph{Coalgebraic completeness theorems}

\subparagraph{Axiomatisations of behavioural metrics}

% This just dumps some pseudolatin in so you can see some text in place.

