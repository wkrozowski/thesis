\chapter{Introduction}
\label{chapter:introduction}
One of the motivations for the mathematical study of the models of computation stems from the desire for precise and formal reasoning about the correctness of computer systems. These theoretical foundations enable formal verification experts to prove that systems deployed in safety-critical areas, such as avionics or healthcare, behave as expected. In theoretical computer science it is customary to model computations as state transition systems, which are discrete models where a set of states is equipped with a notion of one-step observable behaviour, describing how the system evolves. Typical examples include finite automata, Kripke frames, and Markov chains among many others. 

	This central topic of this thesis are axiomatisations of behaviour of transition systems. By this we mean providing expression languages for representing the behaviour of transition systems and the study of formal systems for reasoning about equivalence or similarity of behaviours represented by expressions of the interest. 
	
	The interest in axiomatising behaviour of transition systems originates from the seminal work of Kleene on regular expressions~\cite{Kleene:1951:Representation}.  In his influential paper from 1951, Kleene introduced deterministic finite automata (DFAs), which are the fundamental model of sequential deterministic computations. Each state of a DFA can be associated with a formal language, a collection of strings that are accepted starting from a given state. This characterises an important class of formal languages, known as regular languages. Classically, two states are equivalent if they recognise the same language. In the same paper, Kleene proposed regular expressions, which are an algebraic specification language for DFAs and proved that both formalisms are equally expressive through a result known nowadays as Kleene’s theorem. As an open problem, he left a completeness question: are there a finite number of rules that enable reasoning about language equivalence of regular expressions? 

Shortly after Kleene's paper, Redko~\cite{Redko:1964:Defining} demonstrated that one cannot use a finite number of equational axioms to axiomatise the language equivalence. But the search for axiomatisation made of more expressive rules continued. The first answer came in 1966 from Salomaa~\cite{Salomaa:1966:Two}, who presented two axiom systems. One was infinitary, and the other used finite equations along with an implicational rule encoding Arden's lemma~\cite{Arden:1961:Delayed} for formal languages. While Salomaa's implicational axiomatisation later became a blueprint for inference systems for reasoning about semantic equivalence or similarity of transition systems, this formal system was not algebraic. Essentially, the implicational rule relied on the productivity side-condition called empty word property (EWP) that caused the resulting axiomatisation to be unsound under substitution of letters by arbitrary expressions. This problem has motivated several researchers including Conway~\cite{Conway:2012:Regular}, Krob~\cite{Krob:1990:Complete} and Boffa~\cite{Boffa:1990:Une} to pursue the problem of obtaining algebraic axiomatisation of language equivalence of DFAs, eventually leading to the celebrated completeness result of Kozen~\cite{Kozen:1994:Completeness}. The inference system of Kozen is known nowadays under the name Kleene Algebra (KA) and it forms a basis of several formal systems for equational reasoning about imperative programs~\cite{Kozen:1996:Kleene}, packet-passing software defined networks~\cite{Anderson:2014:NetKAT}, and concurrent programs~\cite{Kappe:2017:Concurrent,Wagemaker:2019:Completeness} among many others.

Besides DFAs, automata theorists have studied many variants of automata, including nondeterministic~\cite{Rabin:1959:Finite}, weighted~\cite{Schutzenberger:1961:Definition} and probabilistic~\cite{Rabin:1963:Probabilistic} ones, usually focusing on the notion of language equivalence or inclusion. At the advent of process algebra in the 1980s, Milner and Park brought the concept of bisimilarity~\cite{Park:1981:Concurrency}, a notion of equivalence finer than language equivalence, that was motivated by the needs of the study of concurrency theory and models such as labelled transition systems (LTSs). Essentially, language equivalence is a linear-time notion, as it hides the precise moment of resolving nondeterministic choice from the external observer. At the same time, bisimilarity allows for a more fine-grained comparison of behaviours by looking at the exact moment of resolving the nondeterministic choice. 

Milner~\cite{Milner:1984:Complete} considered a variant of LTSs that he called charts and studied the associated problem of axiomatising the bisimilarity of charts. Interestingly, while the syntax of regular expressions can be used to specify behaviours of charts, it is not expressive, that is there exist behaviours that cannot be specified using Kleene's syntax. Instead, Milner proposed a more general language called the algebra of regular behaviours (ARB) featuring binders, action prefixing, and a recursion operator. The paper introducing ARB also provided a suitable generalisation of Salomaa's non-algebraic axiomatisation and demonstrated its soundness and completeness with respect to the bisimilarity of charts.   

The completeness results of Salomaa, Kozen, and Milner mentioned above are prototypical instances of the vast strain of research that has been of particular interest to theoretical computer scientists for decades. Given a transition system model and an associated notion of semantic equivalence, having a complete axiomatisation allows one to reason about model behaviour through the syntactic manipulation of terms of the specification language, which is well-suited for implementation, automation, and formal reasoning. Each time when the needs of modelling computer systems result in a new transition system model or an associated notion of semantic equivalence, it is natural to ask about the complete axiomatisation. 

This thesis provides contributions to the above outlined field of axiomatisations of behaviours of transition systems in two orthogonal directions.
\begin{enumerate}
	\item The first part of the thesis is concerned with the study of formal systems for quantitative reasoning about behavioural distances, that replace conventional notions of behavioural equivalence with a quantitative measure of how close the behaviour of two states of transition systems is.
	\item The second part focuses on probabilistic transition systems and presents a sound and complete axiomatisation of language equivalence of behaviours specified through the syntax of Probabilistic Regular Expressions.
	\end{enumerate}	
We now provide a brief outline of each of these directions.
\section{Behavioural Distances}
In many contexts, especially when dealing with probabilistic or quantitative models, focusing on exact equivalence of behaviours such as language equivalence or bisimilarity is too restrictive. A tiny perturbation in observed probability or weights of transition can deem two states inequivalent.  Instead, it is often more meaningful to measure how far apart the behaviours of two states are. 

This has motivated the development of behavioural distances, which endow the state spaces of transition systems with (pseudo)metric spaces quantifying the dissimilarity of states. In such a setting, states at distance zero are not necessarily the same, but rather equivalent with respect to some classical notion of behavioural equivalence. In a nutshell, equipping transition systems with such a notion of distance crucially relies on the possibility of lifting the distance between the states to the distance on the one-step observable behaviour of the transition system.

Behavioural distances first appeared in the context of probabilistic transition systems~\cite{Desharnais:2004:Metrics,Breugel:2001:Towards}, where one-step observable behaviour forms a probability distribution. In such a setting, in order to lift distances from the state space to one-step observable behaviour, one can rely on the classic Kantorovich lifting from transportation theory~\cite{Villani:2009:Optimal}. 

More generally, behavioural distances are not limited to probabilistic or weighted systems; instead, they can be defined meaningfully for a variety of transition systems~\cite{Baldan:2018:Coalgebraic}. One of the simplest instances is deterministic finite automata, which can be equipped with a shortest-distinguishing-word distance~\cite{Bonchi:2018:UpTo}, where the longer the smallest word that can witness inequivalence of two states is, the closer the behaviour of compared states is. To illustrate that, given an alphabet $\alphabet = \{a\}$, we have that a state recognising the language $\{a,aa, aaa\}$ is closer to the one recognising $\{a,aa,aaa,aaa\}$ rather than $\{a\}$. 

The study of axiomatisations of behavioural distances have mainly focused on concrete probabilistic cases~\cite{Bacci:2018:Bisimilarity,Bacci:2018:TV,Bacci:2018:Algebraic}. Axiomatisations of other important instances of behavioural distances are still underexplored. The main goal of the first part of this thesis is to initiate the study of axiomatisations and completeness problems for behavioural distances beyond the concrete probabilistic instances. Our starting point is the work of Bacci, Bacci, Larsen and Mardare~\cite{Bacci:2018:Bisimilarity}, who gave a sound and complete axiomatisation of branching-time behavioural distance of terms of a probabilistic process calculus.

\section{Probabilistic Language Equivalence}
In 1963, Rabin introduced probabilistic automata~\cite{Rabin:1963:Probabilistic}. This model captures the simple notion of randomised computation and acts as an acceptor for probabilistic languages. Under such semantics, each word over some fixed alphabet is associated with a weight from the unit interval capturing how likely the word is to be accepted. Throughout the years, Probabilistic Automata were deeply studied from an algorithmic point of view~\cite{Kiefer:2011:Language} that eventually enabled the development of practical verification tools for randomised programs~\cite{Kiefer:2012:APEX}. 

In the process algebra community, Larsen and Skou~\cite{Larsen:1991:Bisimulation} devised a notion of probabilistic bisimilarity, while Stark and Smolka~\cite{Stark:2000:Complete} provided a probabilistic process calculus featuring binders and a recursion operator and gave a sound and complete axiomatisation of probabilistic bisimilarity of terms of their calculus. The later work of Silva and Sokolova~\cite{Silva:2011:Sound} showed that one can extend Stark and Smolka's system with additional axioms characterising probabilistic language equivalence to obtain a complete axiomatisation of language equivalence.

While the result of Silva and Sokolova enables the use of the process algebraic syntax of Stark and Smolka for reasoning about probabilistic language equivalence, it is natural to ask if one could devise a simpler, binder-free specification language in the style of Kleene's Regular Expressions and provide a more streamlined axiomatisation in the style of Salomaa.
	
	This problem is the central motivation for the second part of this thesis. One of the main inspirations for that comes from the probabilistic pattern matching community, where researchers already considered Regular Expression-like operations to specify probabilistic languages~\cite{Ross:2000:Probabilistic}. They did so by replacing the union of languages and Kleene's star from the usual Regular Expression with their probabilistic counterparts, which respectively can be seen as a convex combination and a form of the Bernoulli process. At the same time, the precise connection of such syntaxes to the transition systems model was under-explored~\cite{Beeh:2017:Transformations} and the topic of axiomatisation was not tackled at all. 


\section{Coalgebra}
Both behavioural distances and probabilistic language equivalence can be studied abstractly through the unifying framework of the universal coalgebra~\cite{Gumm:2000:Elements,Rutten:2000:Universal}. Coalgebras provide an abstract and uniform treatment of transition systems through the language of category theory. Generally speaking, transition systems can be seen as pairs consisting of a set of states and a transition function, mapping each state to its one-step behaviour. The coalgebraic outlook allows abstracting away the features of the one-step behaviour of the transition system, such as inputs, labels, nondeterminism, probability, and the like through the notion of a type, formally modelled as an endofunctor on the category of sets and functions. Given a type functor, one can uniformly instantiate abstract results concerning the transition systems of the interest. 

In particular, each type of functor canonically determines a notion of behavioural equivalence of states. Under mild set-theoretic size constraints on the type functor, one can construct a final coalgebra, which provides a universal domain of behaviours of transition systems of interest. For example, the final coalgebra for the functor describing deterministic automata is isomorphic to the set of all formal languages over some alphabet~\cite{Rutten:2000:Universal}. Concrete instances of coalgebraic behavioural equivalence usually capture variants of bisimilarity and coincide with the notions known for the literature such as bisimilarity of LTSs or probabilistic bisimilarity of Larsen and Skou~\cite{Vink:1999:Bisimulation}.  
		
	Modelling finer notions of semantic equivalence can be phrased by changing the base category over which the type functor is defined to a more structured setting than sets and functions. For example, one of the ways to model probabilistic language equivalence in the language of coalgebra is to work with coalgebras for an appropriate type functor over the category of positive convex algebras~\cite{Silva:2010:Generalizing,Silva:2011:Sound}. In this category, the final coalgebra is precisely carried by the set of all probabilistic languages over some alphabet. 	 

At the same time, the recent work on coalgebraic behavioural distances~\cite{Baldan:2018:Coalgebraic} provided a categorical generalisation of Kantorovich lifting to lifting endofunctors over the category of sets to the category of pseudometric spaces and nonexpansive maps between them. Final coalgebras for type functors obtained through such liftings come equipped with a pseudometric between behaviours. Such a coalgebraic outlook enables generalising the notions of behavioural distances beyond probabilistic transition systems and is extensively used in the first part of the thesis.

Using the theory of universal coalgebra for axiomatisation problems allows abstracting away the generic steps of completeness theorems and instantiating abstract categorical results to obtain concrete properties of transition systems of interest. For example, the recently developed theory of rational fixpoints~\cite{Milius:2010:Sound} for coalgebras for proper functors~\cite{Milius:2018:Proper} provides a useful generalisation of the notion of regular languages to coalgebraic generality. One of the concrete instances of such a theory enables characterising the analogue of regular languages in the case of probabilistic languages~\cite{Sokolova:2018:Proper} and underpins key results in the second part of the thesis.


\section{Overview of the thesis}
Having outlined the scope and the main aims of this thesis, we summarise below the content of each chapter of the thesis and provide references to the main technical results. The description of each content chapter contains a table providing a high-level overview of the studied axiomatisation problem.
\subparagraph{Chapter 2} presents a sound and complete axiomatisation of \emph{shortest-distinguishing-word} distance between formal languages represented by regular expressions.
 The axiomatisation relies on a recently developed quantitative analogue of equational logic~\cite{Mardare:2016:Quantitative}, allowing manipulation of rational-indexed judgements of the form $e \disteq{\e} f$ meaning the distance between terms $e$ and $f$ is less or equal to $\e$. The technical core of the chapter is dedicated to the completeness argument that draws techniques from order theory and Banach spaces to simplify the calculation of the behavioural distance to the point it can be then mimicked by axiomatic reasoning. 
 
\begin{center}

\begin{tabular}{ m{3cm}|m{10cm}}
  \hline
  \multicolumn{2}{c}{Summary of \Cref{chapter2}}\\
  \hline
  Model & deterministic finite automata (DFA)\\
  Syntax & $e,f \in \RExp ::= \zero \mid \one \mid a \in \alphabet \mid e + f \mid e \seq f \mid e^\ast$ \\
  Semantics & shortest-distinguishing-word distance of languages \\
  Example fact & $a^\ast \disteq{1/4}a + \one $\\
  Soundness & \Cref{c2:thm:soundness} \\
  Completeness	& Theorem \Cref{c2:completeness} \\
  \hline
\end{tabular}
\end{center}
This chapter incorporates results from the following paper:

\begin{quote}
\printpublication{Rozowski:2024:Complete}
\end{quote}

\subparagraph{Chapter 3} describes a sound and complete axiomatisation of a behavioural metric for nondeterministic processes using Milner's charts~\cite{Milner:1984:Complete}---a model that generalises finite-state automata by incorporating variable outputs. Charts provide a compelling setting for studying behavioural distances because they shift the focus from language equivalence to bisimilarity.

To formalise this approach, we adopt string diagrams~\cite{Selinger_2010,piedeleu2023introduction} as our syntax of choice. String diagrams closely mirror the graphical structure of charts, while providing a rigorous formalism that supports inductive reasoning and compositional semantics. Unlike traditional algebraic syntaxes, which require additional mechanisms such as binders and substitution, string diagrams offer a variable-free representation where recursion naturally decomposes into simpler components. This makes them well-suited for reasoning about behavioural distances and aligns with broader efforts to axiomatise automata-theoretic equivalences through a unified diagrammatic framework~\cite{piedeleu2023finite,antoinecsl2025}.
\begin{figure}
	
\end{figure}
\begin{center}
\begin{tabular}{ m{3cm}|m{10cm}}
  \hline
  \multicolumn{2}{c}{Summary of \Cref{chapter3}}\\
  \hline
  Model & Milner's charts~\cite{Milner:1984:Complete}\\
  Syntax & $\tikzfig{lr-copy}\quad\tikzfig{lr-delete}\quad\tikzfig{lr-merge}\quad\tikzfig{lr-generate} \quad\tikzfig{cap-down} \quad\tikzfig{cup-down}\quad \scalar{a} \quad (a\in \alphabet)$ \\
  Semantics & bisimulation distance of regular behaviours\\
  Example fact & $\tikzfig{ex-diag-1-l} \disteq{1/4} \tikzfig{a-star-b}$\\
  Soundness & Theorem \Cref{c2:soundness} \\
  Completeness	& Theorem \Cref{c2:completeness} \\
  \hline
\end{tabular}
\end{center}
The findings presented in this chapter are the content of the following paper:

\begin{quote}
\printpublication{Rozowski:2025:Diagrammatic}
\end{quote}

\subparagraph{Chapter 4} introduces Probabilistic Regular Expressions (PRE), a probabilistic analogue of regular expressions denoting probabilistic languages in which every word is assigned a probability of being generated.  PRE are formed through constants from an alphabet and regular operations of probabilistic choice, sequential composition, probabilistic Kleene star, identity and emptiness.  We present and prove the completeness of an inference system for reasoning about probabilistic language equivalence of PRE based on Salomaa’s axiomatisation of language equivalence of regular expressions. The technical core of the chapter is devoted to the completeness proof, which relies on technical tools from the theory of convex algebra~\cite{Sokolova:2018:Proper}, arising from the rich structure of probabilistic languages. 
\begin{center}
\begin{tabular}{ m{3cm}|m{10cm}}
  \hline
  \multicolumn{2}{c}{Summary of \Cref{chapter4}}\\
  \hline
  Model & generative probabilistic transition systems~\cite{Glabbeek:1995:Reactive}\\
  Syntax & $e,f \in \PExp ::= \zero \mid \one \mid a \in \alphabet \mid e \oplus_p f \mid e \seq f \mid e^{\left[ p \right]}$ \\  Semantics & probabilistic language equivalence \\
  Example fact & $a \seq a^{\left[1/4\right]} \equiv a \oplus_{3/4} \left( a \seq a^{\left[1/4\right]}\seq a\right)$\\
  Soundness & Theorem \Cref{c2:soundness} \\
  Completeness 	& Theorem \Cref{c2:completeness} \\
  \hline
\end{tabular}
\end{center}
The results described in this chapter were published in the paper referenced below:

\begin{quote}
\printpublication{Rozowski:2024:Completeness}
\end{quote}
\noindent
\textbf{Chapter 5} sketches directions for the future work and concludes this thesis.

%This is prepared to be used in new variants of conclusion chapters
%\section{Related work}
%In this section, we survey the main strands of the related work, while we relegate the more detailed discussion to the respective content chapters. 
%\subparagraph{Axiomatisations of behavioural distances.} Early works on axiomatising behavioural distances relied on ad-hoc inference systems. An earliest example of such system was presented by Larsen, Fahrenberg and Thrane~\cite{Larsen:2011:Metrics}, who focused on directed simulation distance of streams of elements equipped with a metric space structure. Later work of D'Argenio, Gebler and Lee~\cite{Argenio:2014:Axiomatizing} studied systematic axiomatisations of behavioural between processes featuring both probability and nondeterminism definable through the PGSOS rule format. It is important to note that the inference system of D'Argenio et al contained a powerful rule internalising the definition of Kantorovich lifting as an inference rule.
%
%The introduction of quantitative equational theories~\cite{Mardare:2016:Quantitative} made more principled approaches possible. Bacci, Mardare, Panangaden and Plotkin~\cite{Bacci:2018:Algebraic} axiomatised bisimilarity metric of Markov processes~\cite{Desharnais:2004:Metrics} and in the later work similarly considered behavioural distance of Mealy machines and Markov decision processes~\cite{Bacci:2024:Sum}. Those results crucially hinged on the quantitative generalisations of results from universal algebra, such as the notion of the tensor of algebraic theories. It is worth noting that specification languages used in those axiomatisations did not feature separate primitives for introducing recursion.
%
%An alternative approach was proposed by Bacci, Bacci, Larsen and Mardare~\cite{Bacci:2018:Bisimilarity}, who used a mild relaxation of quantitative equational theories and gave a sound and complete axiomatisation of bisimulation distance between terms of probabilistic process calculus of Stark and Smolka~\cite{Stark:2000:Complete} and later adapted their results to a coarser notion of total variation distance between infinite traces~\cite{Bacci:2018:TV}. 
%
%\subparagraph{Coalgebraic completeness theorems.} The usage of coalgebra in axiomatising behavioural equivalences dates back to the paper of Jacobs~\cite{Jacobs:2006:Bialgebraic}, who rephrased the classical Kozen's completeness result for Kleene Algebra in a coalgebraic setting. Crucially, Jacobs showed that Kozen's argument is equivalent to establishing an appropriate universal property characterising behaviours of finite-state systems. Relying on the same pattern, Silva~\cite{Silva:2010:Kleene} introduced Kleene coalgebra, a modular framework for complete axiomatisations of the coalgebraic behavioural equivalence of coalgebras for Kripke polynomial functors and later extended the results to a wide class of weighted transition systems~\cite{Bonchi:2009:Deriving}. Shortly after that, Myers~\cite{Myers:09:Coalgebraic} described the connection between the process algebraic syntaxes used in the framework of Silva and the coalgebraic $\mu$-calculus~\cite{Cirstea:2009:Exptime} and provided a tableaux-based decision procedure. Within the same research tradition, the thesis of Schmid~\cite{Schmid:2024:Coalgebraic} studied axiomatisations of coalgebraic behavioural equivalence of effectful process algebra, a generalisation of Milner's algebra of regular behaviours, where the nondeterministic branching of charts is replaced with arbitrary algebraic theories. 
%
%	It is worth noting that all the works mentioned above axiomatise the canonical behavioural equivalence of coalgebras for type functors over the category of sets, which usually coincides with the variants of bisimilarity. In terms of axiomatising coarser notions than bisimilarity, Milius~\cite{Milius:2010:Sound} gave a complete axiomatisation of equivalence of finite dimensional linear systems that can be abstractly seen as a behavioural equivalence for coalgebras for an appropriate type functor over the category of vector spaces. Milius's completeness argument crucially relied on the theory of locally finite and accessible categories~\cite{Adamek:1994:Locally} to characterise the so-called rational fixpoint, an abstract domain for finite behaviour generalising regular languages. Later, Bonsangue, Milius and Silva~\cite{Bonsangue:2013:Sound} used an analogous strategy to obtain a modular axiomatisation of language equivalence of weighted automata over Noetherian semirings, by working with coalgebras for functors over the category of semiring semimodules. Through a similar blueprint, Silva and Sokolova~\cite{Silva:2011:Sound} gave a complete axiomatisation of probabilistic language equivalence, by working with coalgebras with an additional positive convex algebra structure.            




	
% This just dumps some pseudolatin in so you can see some text in place.

